---
layout: post
title: Dual-Domain Triple Contrast for Unsupervised Domain Adaptation
author: Kun Wang
tags:
  - paper
  - unsupervised domain adaptation
  - contrastive learning
  - skeleton-based action recognition
date: '2025-01-30 14:30 +0800'
---

Unsupervised Domain Adaptation (UDA) methods learn from labeled data within source domain and unlabeled data within target domain, and then perform downstream tasks on target domain. Current methods approach UDA task using domain adaptation or self-supervised learning strategies, while our D2TC leverages contrastive learning to integrate both strategies into a unified framework. D2TC is used to perform cross-dataset skeleton-based action recognition for practice evaluation.

![]({{site.baseurl}}/assets/d2tc.png)

## Paper Info
- **Title**: Dual-Domain Triple Contrast for Cross-Dataset Skeleton-based Action Recognition
- **Author(s)**: K Wang, J Cao, J Ge, C Liu, B Liu
- **Conference/Journal Name**: ACM Transactions on Multimedia Computing Communications and Applications (TOMM)
- **Date**: 2025
- **Link**: [Waiting Online](https://)
- **GitHub**: [D2TC](https://github.com/KennCoder7/D2TC)
  
## Abstract
Skeleton-based Action Recognition (SAR) is widely recognized for its robustness and efficiency in human action analysis, but its performance in cross-dataset tasks has been limited due to domain shifts between different datasets. To address this challenge, current methods typically approach cross-dataset SAR as an Unsupervised Domain Adaptation (UDA) task, which is tackled using domain adaptation or self-supervised learning strategies. In this paper, we propose a Dual-Domain Triple Contrast (D2TC) framework for cross-dataset SAR under the UDA setting. Unlike existing UDA methods that either focus on a single strategy or superficially combine strategies, our D2TC leverages contrastive learning to integrate both strategies into a unified framework. It performs three types of contrastive learning: Self-Supervised Contrastive Learning (SS-CL), Supervised Contrastive Learning (Sup-CL), and Unsupervised Domain Adaptation with Contrastive Learning (UDA-CL), across both source and target domains. The triple contrasts go beyond mere summation, effectively bridging the domain gap and enhancing the model's representational capacity. Additionally, we introduce multi-modal ensemble contrast and extreme skeleton augmentation methods to further enhance the skeleton-based representation learning. Extensive experiments on six cross-dataset settings validate the superiority of our D2TC framework over state-of-the-art methods, demonstrating its effectiveness in reducing domain discrepancies and improving cross-dataset SAR performance.

## Citation
If you find this idea helpful, please consider citing:
```
The paper was accepted at Jan-26, 2025, now is waiting online.
```
